{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMX2ALvEzBrfoEH9/RGY7QR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mostakimjihad/EnFER-ViT/blob/main/EnFER_ViT(RAF_DB%2C_AfffectNet).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daqJsCyo51mQ"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "\n",
        "# FER_2013_DATASET_PATH = kagglehub.dataset_download(\"msambare/fer2013\")\n",
        "RAF_DB_DATASET_PATH = kagglehub.dataset_download(\"shuvoalok/raf-db-dataset\")\n",
        "print(RAF_DB_DATASET_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_path = RAF_DB_DATASET_PATH + '/DATASET//train'\n",
        "test_path = RAF_DB_DATASET_PATH + '/DATASET//test'\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1/255.0,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    rotation_range=15\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(100, 100),\n",
        "    color_mode='rgb',\n",
        "    batch_size=16,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.0)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_path,\n",
        "    target_size=(100, 100),\n",
        "    color_mode='rgb',\n",
        "    batch_size=16,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "MkjDdcCz6bqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import EfficientNetB4\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization, Reshape, GlobalAveragePooling1D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import LayerNormalization, MultiHeadAttention, Add\n",
        "\n",
        "\n",
        "efficientnet = EfficientNetB4(weights='imagenet', include_top=False, input_shape=(100, 100, 3))\n",
        "\n",
        "for layer in efficientnet.layers[-20:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "def transformer_encoder(inputs, num_heads=4, key_dim=32, ff_dim=128, dropout=0.1):\n",
        "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)(inputs, inputs)\n",
        "    attn_output = Dropout(dropout)(attn_output)\n",
        "    out1 = Add()([inputs, attn_output])\n",
        "    out1 = LayerNormalization(epsilon=1e-6)(out1)\n",
        "\n",
        "    ffn = Dense(ff_dim, activation='relu')(out1)\n",
        "    ffn = Dense(inputs.shape[-1])(ffn)\n",
        "    ffn_output = Dropout(dropout)(ffn)\n",
        "    out2 = Add()([out1, ffn_output])\n",
        "    return LayerNormalization(epsilon=1e-6)(out2)\n",
        "\n",
        "\n",
        "input_tensor = Input(shape=(100, 100, 3))\n",
        "efficientnet_features = Flatten()(efficientnet(input_tensor))\n",
        "\n",
        "combined_features = Dense(512, activation='relu', kernel_regularizer=l2(1e-4))(efficientnet_features)\n",
        "combined_features = Dropout(0.2)(BatchNormalization()(combined_features))\n",
        "\n",
        "sequence_length = 16\n",
        "embedding_dim = combined_features.shape[-1] // sequence_length\n",
        "reshaped_features = Reshape((sequence_length, embedding_dim))(combined_features)\n",
        "\n",
        "\n",
        "transformer_output = transformer_encoder(reshaped_features, num_heads=4, key_dim=embedding_dim, ff_dim=128, dropout=0.1)\n",
        "pooled_output = GlobalAveragePooling1D()(transformer_output)\n",
        "\n",
        "\n",
        "output_tensor = Dense(7, activation='softmax')(pooled_output)\n",
        "\n",
        "\n",
        "model = Model(inputs=input_tensor, outputs=output_tensor)\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "nqTE6Wpu6ID-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training with Callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=30,\n",
        "    validation_data=test_generator,\n",
        "    batch_size=16,\n",
        "    callbacks=[early_stopping, lr_scheduler]\n",
        ")"
      ],
      "metadata": {
        "id": "_8fwR3Ak7Bw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(accuracy) + 1)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, accuracy, label='Training Accuracy', marker='o')\n",
        "plt.plot(epochs, val_accuracy, label='Validation Accuracy', marker='o')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig('QoEOne.pdf')\n",
        "files.download(\"QoEOne.pdf\")\n",
        "\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, loss, label='Training Loss', marker='o', color='red')\n",
        "plt.plot(epochs, val_loss, label='Validation Loss', marker='o', color='orange')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Show the plots\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "L7zBOIPv7DfJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}